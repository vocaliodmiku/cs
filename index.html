<!DOCTYPE HTML
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html>

<head>
  <!-- <div class="navbar">
		<a href="./index.html"><font size="+1">Home</font></a>
		<a href="./publication.html"><font size="+1">Publications</font></a>
    <a href="./teach.html"><font size="+1">Teaching</font></a>
    <a href="./awards.html"><font size="+1">Awards</font></a>
		<a href="./misc.html"><font size="+1">Misc</font></a>
	</div> -->
  <title>Linkai Peng</title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <link rel="stylesheet" type="text/css" href="style.css" />
</head>

<body style="color: rgba(0, 0, 0, 0.938);margin:0;padding:0">
  <div id="wrapper">
    <div id="content-wrap">
      <div id="content">
        <div id="main">
          <tr>
            <p style="padding-right:30px;"> <img id="headshot" "float-left" align="left" alt="plk"
                src="images/profile.png" width="180" height="185" /></p>

            <p>
              <font size="+3"><strong>&nbsp;Linkai Peng</strong></font>
            </p>
            <p></p>
            <p style="line-height:90%">
              <font size="3"><a href="" style="color:#9B0145;">&nbsp;&nbsp;NetEase Youdao</a></font>
            </p>
            <p style="line-height:90%">
              <font size="3">&nbsp;&nbsp;Beijing, China</font>
            </p>
            <p style="line-height:90%">
              <font size="3"><strong>&nbsp;&nbsp;Email:</strong> penglinkai96@gmail.com | penglinkai@corp.netease.com
              </font>
            </p>

            <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
            &nbsp;&nbsp;&nbsp;&nbsp;<a href="https://scholar.google.com/citations?user=v8G7pHoAAAAJ"><i
                class="ai ai-google-scholar ai-2x" style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <link rel="stylesheet"
              href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
            <a href="https://github.com/vocaliodmiku"><i class="fa fa-github"
                style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <a href='https://www.researchgate.net/profile/Peng-Linkai-3'><i class="ai ai-researchgate ai-2x"
                style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <a href='pdfs/LinkaiPeng.pdf'><i class="ai ai-cv ai-2x"
                style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <!-- <p></p> -->
          </a>
          </tr>
          <hr style="color:rgb(218, 218, 218);">

          <h1><a name="biography">About Me</h1>
          <p>Hi, this is Linkai Peng. I am an ML engineer @ NetEase YouDao, where a central focus of my work is
            <a style="color:#b04605;">developing Large Language Models(LLMs) and Unsupervised speech Model to improve Language Learning system. </a>
            Recently, I am developing speech assessment system in a Conversational AI teacher <a href="https://hiecho.youdao.com/#/web">Hi Echo!</a>. My research interests lie in the areas of <b> Human-Computer Interaction, Speech Processing and educational AI.</b> A good presentation method will stimulate people's interest in learning, especially when it comes to sound.
          <dl style="background-color:#b9a2100f">
            <p></p>
            <p style="font-size:18px">&#128204; <a style="color:#6c3a3af2;"><b>Research Themes Overview</b></a></p>
            <ul>
              <li> <font size="3"> <b>Speech Data Interaction:</b>  <p> Presenting sound or music along with their visualizations would create a marvelous audio-visual experience. Below is an embed that I find incredibly engaging. <a href="https://isca-speech.org/archive/pdfs/interspeech_2021/peng21e_interspeech.pdf" style="color:#b04605;">[source website]</a></p>
                </font>
                <!-- 我对来自数据可视化的兴趣由来已久，特ß别是当我遇到这个网站。以下是一个嵌入，我觉得这个非常好玩 -->
                <iframe
                  src="https://musiclab.chromeexperiments.com/Kandinsky/"
                  width="800"
                  height="500">
                </iframe>
                <p>In language learning, effective visualization is key to fostering learning interest. For example, the image below illustrates an idea to automatically segment audio into different chunks based on semantics, aimed at aiding users in practicing listening skills. The text is initially masked, and users can uncover the parts corresponding to grammar structures they find challenging.</p>
                <img src="images/20231207-024138.jpg" width="550" style="border: 0;">

              </li>
              <li> <font size="3"> <b>Non-native Speech Processing:</b> Mispronunciation detection and diagnosis with self supervised model. (<a
                href="https://isca-speech.org/archive/pdfs/interspeech_2021/peng21e_interspeech.pdf" style="color:#b04605;">Linkai et al'2021;</a><a
                href="https://arxiv.org/pdf/2206.07289" style="color:#b04605;">2022</a></font>)
              <li> <b>Mandarin Tone Recognition:</b> modeling tone with multi-scale temporal-frequency features. (<a
                href="https://www.researchgate.net/profile/Peng-Linkai-3/publication/349802146_Multi-Scale_Model_for_Mandarin_Tone_Recognition/links/647412aca25e543829daa199/Multi-Scale-Model-for-Mandarin-Tone-Recognition.pdf" style="color:#b04605;">Linkai et al'2020;</a>)
            </ul>
          </dl>

          <!-- <dl style="background-color:#b953100c">
            <p></p>
            <p style="font-size:18px"> <a style="color:#6c3a3af2;"><b>Highlights</b></a></p>
            <p style="font-size:16px">&#127891; Received the Outstanding Doctoral Student Award, UVA, 2023</p>
            <p style="font-size:16px">&#127881; Received the John A. Stankovic Graduate Research Award, UVA, 2023</p>
            <p style="font-size:16px">&#127881; I was awarded the Carlos and Esther Farrar Fellowship, 2022 - 2023</p>
            <p style="font-size:16px">&#128105;&#8205;&#127979; As the primary instructor, I co-designed and taught the
              course, <a href="https://uvanlp.org/iml-2022/" target="_blank" style="color:#9B0145;">CS 6501/4501
                Interpretable Machine Learning</a>, at UVA in Spring 2022, and was awarded the UVA CS Outstanding
              Graduate Teaching Award and University-wide Graduate Teaching Awards Nominee (<b>top 5%</b> of graduate
              instructors)</p>
            <p style="font-size:16px">&#128221; My collaborators and I are actively updating a <a
                href="https://github.com/HanjieChen/Reading-List/wiki" style="color:#9B0145;">Reading List</a> with
              interesting papers</p>
            <p></p>
          </dl> -->

          <dl style="background-color:rgba(230, 199, 243, 0.13)">
            <p></p>
            <a style="color:#6c3a3af2; font-size:18px"><b>&nbsp;&nbsp;Updates</b></a>
            <div class="myBox">
              <ul>
                <!-- <li> [11/2023] The setup of two research project pages has been completed [<a href="https://vocaliodmiku.github.io/deep-speech-model-and-human-brain/" style="color:#b04605;">Project #1'2023</a><a href="https://vocaliodmiku.github.io/deep-speech-model-and-human-brain/index_cn.html" style="color:#b04605;"> / 中文 </a>| <a href="https://vocaliodmiku.github.io/recover-speech-information-from-brain-recordings/" style="color:#b04605;">Project #2'2023</a>]. If you have similar research interests and relevant background (computer science, cognitive science, and linguistics), please feel free to take a look at them and any suggestions are greatly appreciated. -->

                <li> [08/2023] New preprint [<a
                  href="https://arxiv.org/pdf/2308.14536.pdf" style="color:#9B0145;">ArXiv</a> | <a
                  href="https://vocaliodmiku.github.io/SLI-LL/" style="color:#9B0145;"> Website</a>], <i>Spoken Language Intelligence of Large Language Models for Language Learning</i>, We conducted preliminary explorations on large language models and confirmed through various prompts that text-based large language models (LLM, e.g. ChatGPT, GPT4, LLaMa2) have a good understanding of concepts in phonetics, phonology, and second language acquisition. <br><b>We look forward to LLM with speech modality in their performance!</b>
              </ul>
            </div>
          </dl>

          <p></p>
          <h1><a name="activities">Research Experience</h1>
          <!-- <b><font size="+1">&nbspService</b> -->
          <ul>
            <li> <b>NetEase</b>, Beijing, China, July 2022 - Now
              <p><i>YouDao Group</i></p>
              <ul>
                <li> Artificial Intelligence Engineer
              </ul>
            <li> <b>ByteDance AI-Lab</b>, Beijing, China, November. 2020 - February. 2021
              <p><i> </i></p>
              <ul>
                <li> Research Intern
              </ul>
            <li> <b>Beijing Language and Culture University</b>, Beijing, China, September. 2019 - June. 2022
              <p><i>Speech Acquisition and Intelligent Technology Lab</i></p>
              <ul>
                <li> Research Assistant
          </ul>
          <!-- <h1><a name="activities">Professional Service</h1>
          <!-- <b><font size="+1">&nbspService</b>  
          <ul>
            <li> <b>Organizer</b>: BlackboxNLP 2024
            <li> <b>Diversity Representative</b> for UVA Computer Science Graduate Student Group (CSGSG) Council, 2022
            <li> <b>Area Chair</b> for WiML Workshop @ NeurIPS 2022
            <li> <b>Program Committee</b>: ACL 2023, AAAI 2023, EMNLP 2021 - 2023, NAACL 2021, EACL 2023, CoNLL 2021 -
              2022, NLPCC 2022, ACL DialDoc Workshop 2022, EMNLP BlackboxNLP Workshop 2021, 2023, NeurIPS Explainable AI
              Approaches for Debugging and Diagnosis Workshop 2021, Document-grounded Dialogue Workshop 2021, MASC-SLL
              2020
            <li> <b>Reviewer</b>: TACL 2023 - 2025, ICLR 2024, NeurIPS 2023, EMNLP 2023, ACL Rolling Review 2021 - now,
              ACL 2020 - 2021, EMNLP BlackboxNLP Workshop 2022, CoNLL 2019 - 2020, NLPCC 2019 - 2021
          </ul> -->

          <hr style="color:rgb(218, 218, 218);">
          <div style="text-align: center; font-size: 18px;"><small>Last update: 11/2023. Modified from Website of <a href="https://github.com/HanjieChen/hanjiechen.github.io" style="color:#9B0145;">Prof. Hanjie Chen</a> </small>
          </div>
          <br>
        </div>
      </div>
    </div>
  </div>

</body>

</html>